# Use stages to define stages that contain groups of jobs. Use stage in a job
# to configure the job to run in a specific stage.
stages:
  - test

# Global default environment variables set for all jobs unless overridden by
# job-specific configuration.
variables:
  # Make sure output supports UTF-8
  LC_ALL: "C.UTF-8"
  LANG: "C.UTF-8"

# Global default parameters set for all jobs unless overridden by job-specific
# configuration.
default:
  image: python:3.8
  interruptible: true

###############################################################################
# Run Conditions
#
# In the future, this could be broken out into a separate file that we
# `include` here.
#
# REMINDER: The "." prefix causes the "job" to be hidden (does not get run),
# but can still be used for inheritance.

# Run rules to activate at the major junction points: merge requests, tag
# pipelines and branch pipelines for main.
.run_automatically:
  rules:
    # If changes are make to an active merge request.
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: on_success
    # If changes are pushed for a tag.
    - if: $CI_COMMIT_TAG
      when: on_success
    # If changes are pushed to the default branch.
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: on_success
    - when: never  # explicit fail-exclude terminal condition.

###############################################################################
# Jobs -- Testing
#
# In the future, `.`-prefixed templates could be broken out into a separate
# file that we `include` here.
#
# REMINDER: The "." prefix causes the "job" to be hidden (does not get run),
# but can still be used for inheritance.

# For internal git dependencies
.setup_ci_git: &setup_ci_git
  - git config --global url."https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.jatic.net".insteadof "ssh://git@gitlab.jatic.net"
  - git config --global url."https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.jatic.net/".insteadOf "git@gitlab.jatic.net:"

.poetry_install:
  variables:
    # Change pip's cache directory to be inside the project directory since we
    # can only cache local items. Same for poetry cache
    PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
    POETRY_CACHE_DIR: "$CI_PROJECT_DIR/.cache/poetry"
  # We are only caching the pip/poetry caches, NOT THE VENV. Caches should be
  # python version agnostic.
  cache:
    key: py-package-cache
    paths:
      - $PIP_CACHE_DIR
      - $POETRY_CACHE_DIR
  before_script:
    - export PATH=${HOME}/.local/bin:${PATH}
    # Will make use of .cache/pip
    - pip install --user -U poetry
    - command -v python
    - python --version
    - command -v pip
    - pip --version
    - command -v poetry
    - poetry -V
    - poetry config --local virtualenvs.in-project true
    - *setup_ci_git
    # Will make use of .cache/poetry
    - poetry install --sync

.test_defaults:
  extends:
    - .run_automatically
    - .poetry_install
  stage: test
  image: python:3.8
  interruptible: true
  tags:
    - docker

# Job to lint python code
test-py-lint:
  extends: .test_defaults
  script:
    - poetry run flake8

# Job to typecheck python code
test-py-typecheck:
  extends: .test_defaults
  script:
    - poetry run mypy

test-docs-build:
  extends: .test_defaults
  script:
    - cd docs
    - poetry run make html

# Job to run unittests via pytest
test-pytest:
  extends: .test_defaults
  parallel:
    matrix:
      - PY_VERSION: [ "3.7", "3.8", "3.9", "3.10", "3.11" ]
  image: python:${PY_VERSION}
  script:
    # Install extras for static notebook checking
    - poetry install --all-extras --sync
    - poetry run pytest

# Job to test-run the example jupyter notebooks
#
# This job has a parallel matrix to parameterize different working-directories
# and notebooks within to run. Each parallel instance of this job should only
# run a single notebook. !reference:
#
# See GitLab docs for parallel-matrix functionality:
#   https://docs.gitlab.com/ee/ci/yaml/#parallelmatrix
#
# The parallel-matrix list may have multiple items, and each entry should have
# a pair of keys: "NOTEBOOK_DIR" and "NOTEBOOK_FILE". (Given the documentation
# for the parallel-matrix functionality, combinatorics are only applied within
# an item, not across items.)
# * "NOTEBOOK_DIR" should be a single string that notes the directory in which
#   notebook files should be run in (basically the working directory, generally
#   the directory the notebook lives in). This path should be relative to the
#   root of the repository.
# * "NOTEBOOK_FILE" should be a list of strings that denote the notebook files
#   to be run. These paths path should be relative to the "NOTEBOOK_DIR". Files
#   in this list will be combinatorially combined with the path provided in
#   the associated "NOTEBOOK_DIR" to create a job parameterization instance.
test-notebooks:
  extends: .test_defaults
  variables:
    TORCH_HOME: "${CI_PROJECT_DIR}/.cache/torch"
    HF_DATASETS_CACHE: "${CI_PROJECT_DIR}/.cache/huggingface/datasets"
    TRANSFORMERS_CACHE: "${CI_PROJECT_DIR}/.cache/huggingface/hub"
  tags:
    - docker
  # Merge inherited caches
  cache:
    - !reference [.test_defaults, cache]
    - key: huggingface-cache
      paths:
        - ${TORCH_HOME}
        - ${HF_DATASETS_CACHE}
        - ${TRANSFORMERS_CACHE}
  # Specifying the various notebooks that we want to be tested. Each invocation
  # of this job should try to execute only one notebook via papermill.
  parallel:
    matrix:
      # Sequences combinatorically combine within a list entry
      - NOTEBOOK_DIR: "examples/huggingface"
        NOTEBOOK_FILE: [ "xaitk-huggingface.ipynb" ]
        EXTRAS: [ "huggingface" ]
      - NOTEBOOK_DIR: "examples/mlflow"
        NOTEBOOK_FILE: [ "MNIST_MLFlow_scikit_saliency.ipynb" ]
        EXTRAS: [ "mlflow" ]
      - NOTEBOOK_DIR: "examples/lightning"
        NOTEBOOK_FILE: [ "xaitk-lightning.ipynb" ]
        EXTRAS: [ "lightning" ]
      - NOTEBOOK_DIR: "examples/jatic_toolbox"
        NOTEBOOK_FILE: [
          "jatic-object-detector-protocol.ipynb",
          "jatic-image-classifier-protocol.ipynb"
        ]
        EXTRAS: [ "huggingface jatic" ]
      - NOTEBOOK_DIR: "demos"
        NOTEBOOK_FILE: [ "increment0-demo.ipynb" ]
        EXTRAS: [ "jatic" ]
      - NOTEBOOK_DIR: "examples/gradio"
        NOTEBOOK_FILE: [ "xaitk-gradio.ipynb" ]
        EXTRAS: [ "gradio" ]
  # Using default container image defined above
  script:
    - |
      if [[ -n "${EXTRAS}" ]]
      then
        poetry install --extras "${EXTRAS}" --sync
      fi
    - cd "${NOTEBOOK_DIR}"
    - poetry run papermill
        --progress-bar -k python3 --stdout-file - --stderr-file -
        "${NOTEBOOK_FILE}" /dev/null
