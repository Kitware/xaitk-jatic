{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3524665-f24d-472b-988b-6dc84ff5a42b",
   "metadata": {},
   "source": [
    "# Benchmarking Hugging Face Accelerate/`xaitk-saliency` Integration\n",
    "\n",
    "This notebook utilizes PyTorch's benchmarking capability, along with [`submitit`](https://github.com/facebookincubator/submitit), to anaylze the integration strategy used for Hugging Face Accelerate and `xaitk-saliency`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e9d8fe-17c8-410a-92c8-6d830b59cc4e",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Environment Setup](#environment-setup)\n",
    "* [Benchmarking](#benchmarking)\n",
    "  * [GPU Sweep](#gpu-sweep)\n",
    "  * [Mask Sweep](#mask-sweep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b026b-8ae4-4e15-b044-9625cb795aef",
   "metadata": {},
   "source": [
    "## Environment Setup <a name=\"environment-setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab36330f-3e9c-4679-9b0d-27006a6be5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing xaitk-jatic...\n",
      "Installing xaitk-saliency...\n",
      "Installing smqtk-classifier...\n",
      "Installing Hugging Face datasets...\n",
      "Installing Hugging Face transformers...\n",
      "Installing Hugging Face accelerate...\n",
      "Installing submitit...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install -qU pip\n",
    "print(\"Installing xaitk-jatic...\")\n",
    "!{sys.executable} -m pip install -q ../..\n",
    "print(\"Installing xaitk-saliency...\")\n",
    "!{sys.executable} -m pip install -q xaitk-saliency\n",
    "print(\"Installing smqtk-classifier...\")\n",
    "!{sys.executable} -m pip install -qU smqtk-classifier\n",
    "print(\"Installing Hugging Face datasets...\")\n",
    "!{sys.executable} -m pip install -q datasets\n",
    "print(\"Installing Hugging Face transformers...\")\n",
    "!{sys.executable} -m pip install -q transformers\n",
    "print(\"Installing Hugging Face accelerate...\")\n",
    "!{sys.executable} -m pip install -q accelerate\n",
    "print(\"Installing submitit...\")\n",
    "!{sys.executable} -m pip install -q 'submitit'\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e2857a-78d6-4a9b-a0dc-df71371c323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note PREDICT_SIZE should be >= BATCH_SIZE, due to the way Accelerate distributes data\n",
    "BATCH_SIZE = 25\n",
    "PREDICT_SIZE = 100\n",
    "MASKED_DATA_BATCH_SIZE = 128\n",
    "\n",
    "min_run_time = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97eb8c0b-42e1-4afc-8bff-093ebfca03ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Use JPEG format for inline visualizations\n",
    "%config InlineBackend.figure_format = \"jpeg\"\n",
    "\n",
    "import submitit\n",
    "from submitit.core.core import Executor\n",
    "\n",
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset, get_worker_info\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForImageClassification\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from accelerate.utils import set_seed\n",
    "\n",
    "from scipy.special import softmax\n",
    "from typing import Iterable, Optional\n",
    "from smqtk_classifier.interfaces.classify_image import ClassifyImage\n",
    "from xaitk_saliency.impls.gen_image_classifier_blackbox_sal.slidingwindow import SlidingWindowStack\n",
    "from xaitk_saliency.impls.gen_image_classifier_blackbox_sal.rise import RISEStack\n",
    "from xaitk_saliency.interfaces.gen_image_classifier_blackbox_sal import GenerateImageClassifierBlackboxSaliency\n",
    "\n",
    "# For \"artifact tracking\" (to compare results)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24fad41-b3dc-4c8e-a1a6-18672bccbc88",
   "metadata": {},
   "source": [
    "The following is code from the original integration notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d84bcd-6be4-43ad-9ffc-3f3b4ac80ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def app(\n",
    "    saliency_generator: GenerateImageClassifierBlackboxSaliency,\n",
    "    use_accelerate: bool = True,\n",
    "    display_results: bool = False,\n",
    "    results_filepath: Optional[str] = None,\n",
    "):\n",
    "    class TestDataset(Dataset):\n",
    "        def __init__(self, data):\n",
    "            self.data = data\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                    transforms.Resize((224, 224), antialias=True),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return self.transform(self.data[index])\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "    accelerator = None\n",
    "    if use_accelerate:\n",
    "        # For reproducability\n",
    "        set_seed(42)\n",
    "\n",
    "        # Set up the accelerator\n",
    "        accelerator = Accelerator(even_batches=False)\n",
    "\n",
    "    # Get the model\n",
    "    model_name = \"aaraki/vit-base-patch16-224-in21k-finetuned-cifar10\"\n",
    "    model = AutoModelForImageClassification.from_pretrained(model_name)\n",
    "\n",
    "    # Predicting on a subset of the CIFAR10 Test dataset\n",
    "    ds = load_dataset(\"cifar10\", split=\"test\")\n",
    "    labels = ds.features[\"label\"].names\n",
    "    num_classes = len(labels)\n",
    "    ds_shuffle = ds.shuffle(seed=42)\n",
    "    images = ds_shuffle[0:PREDICT_SIZE][\"img\"]\n",
    "    dataloader = DataLoader(TestDataset(images), batch_size=min(BATCH_SIZE, PREDICT_SIZE))\n",
    "\n",
    "    if accelerator:\n",
    "        # Prepare the model and dataloader for use with accelerate\n",
    "        model, dataloader = accelerator.prepare(model, dataloader)\n",
    "\n",
    "    image_classifier = AccelerateClassifier(model, labels, accelerator, transform=None)\n",
    "\n",
    "    # Generate saliency maps\n",
    "    sal_maps_set = []\n",
    "    for batch in dataloader:\n",
    "        b = batch.cpu().data.numpy()\n",
    "        for img in b:\n",
    "            sal_maps = saliency_generator(np.moveaxis(img, 0, -1), image_classifier)\n",
    "            sal_maps_set.append(sal_maps)\n",
    "\n",
    "    if accelerator:\n",
    "        accelerator.wait_for_everyone()\n",
    "        t_sal_maps_set = torch.Tensor(np.array(sal_maps_set)).to(accelerator.device)\n",
    "        sal_maps_set_gathered = accelerator.gather(t_sal_maps_set)\n",
    "        sal_maps_set_gathered = sal_maps_set_gathered.data.cpu().numpy()\n",
    "    else:\n",
    "        sal_maps_set_gathered = sal_maps_set\n",
    "\n",
    "    # Plot each image in set with saliency maps\n",
    "    if display_results and (accelerator is None or accelerator.is_main_process):\n",
    "        for i in range(len(images)):\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            num_cols = np.ceil(num_classes / 2).astype(int) + 1\n",
    "            plt.subplot(2, num_cols, 1)\n",
    "            plt.imshow(images[i], cmap=\"gray\")\n",
    "            plt.xticks(())\n",
    "            plt.yticks(())\n",
    "\n",
    "            for c in range(num_cols - 1):\n",
    "                plt.subplot(2, num_cols, c + 2)\n",
    "                plt.imshow(sal_maps_set_gathered[i][c], cmap=plt.cm.RdBu, vmin=-1, vmax=1)\n",
    "                plt.xticks(())\n",
    "                plt.yticks(())\n",
    "                plt.xlabel(f\"{labels[c]}\")\n",
    "            for c in range(num_classes - num_cols + 1, num_classes):\n",
    "                plt.subplot(2, num_cols, c + 3)\n",
    "                plt.imshow(sal_maps_set_gathered[i][c], cmap=plt.cm.RdBu, vmin=-1, vmax=1)\n",
    "                plt.xticks(())\n",
    "                plt.yticks(())\n",
    "                plt.xlabel(f\"{labels[c]}\")\n",
    "\n",
    "    # Save results for comparison for examples sake\n",
    "    if results_filepath is not None and (accelerator is None or accelerator.is_main_process):\n",
    "        pickle.dump(sal_maps_set_gathered, open(results_filepath, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "665e2870-b6b4-4b5a-a13a-21ddda7524a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccelerateClassifier(ClassifyImage):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        labels: list,\n",
    "        accelerator: Optional[Accelerator] = None,\n",
    "        transform: Optional[transforms.transforms.Compose] = None,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.accelerator = accelerator\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.labels\n",
    "\n",
    "    class ClassifyImagesDataset(IterableDataset):\n",
    "        def __init__(\n",
    "            self, iterable: Iterable[np.ndarray], device=None, transform: Optional[transforms.transforms.Compose] = None\n",
    "        ):\n",
    "            self._iterable = iterable\n",
    "            self._device = device\n",
    "            self._transform = transform\n",
    "\n",
    "        def __iter__(self):\n",
    "            tnsfm = self._transform\n",
    "            device = self._device\n",
    "\n",
    "            for image in self._iterable:\n",
    "                image = np.moveaxis(image, -1, 0)\n",
    "                if tnsfm:\n",
    "                    item = tnsfm(image)\n",
    "                else:\n",
    "                    item = image\n",
    "                if device:\n",
    "                    item = torch.Tensor(item).to(device)\n",
    "                yield item\n",
    "\n",
    "    def classify_images(self, image_iter):\n",
    "        dataloader = DataLoader(\n",
    "            self.ClassifyImagesDataset(image_iter, self.accelerator.device if self.accelerator else None),\n",
    "            batch_size=MASKED_DATA_BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        self.model.eval()\n",
    "        results = []\n",
    "        for batch in dataloader:\n",
    "            with torch.no_grad():\n",
    "                preds = softmax(self.model(batch).logits.data.cpu().numpy(), axis=1)\n",
    "            results.extend([{la: p for p, la in zip(pred, self.labels)} for pred in preds])\n",
    "\n",
    "        return results\n",
    "\n",
    "    # Required for implementation\n",
    "    def get_config(self):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f20544-42c5-4ef1-a2bf-7126a34cc377",
   "metadata": {},
   "source": [
    "## Benchmarking <a name=\"benchmarking\"></a>\n",
    "\n",
    "We'll benchmark against (1) a varying number of GPUs and (2) a varying number of masks to see how this affects computation time.\n",
    "\n",
    "We'll first define a utility function to more easily submit jobs via submitit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cc6ab60-4b8f-4ae3-b3f0-78de999041dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_app(app, *args, **kwargs):\n",
    "    job = executor.submit(notebook_launcher, *args, **kwargs)\n",
    "    job.results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c187896f-fc1e-401d-b761-26f70e42ce33",
   "metadata": {},
   "source": [
    "### GPU Sweep <a name=\"gpu-sweeip\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a52d51-e702-4779-aea2-ba243d182026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GPU sweep test: 1 GPU\n",
      "Starting GPU sweep test: 2 GPU\n",
      "Starting GPU sweep test: 4 GPU\n",
      "[ GPU Sweep (100 sample images) ]\n",
      "             |   time\n",
      "1 threads: ----------\n",
      "      1 GPU  |  414.8\n",
      "      2 GPU  |  219.5\n",
      "      4 GPU  |  127.4\n",
      "\n",
      "Times are in seconds (s).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_sliding_window = SlidingWindowStack(window_size=(14, 14), stride=(7, 7), threads=4)\n",
    "\n",
    "gpu_benchmark_results = []\n",
    "\n",
    "gpus = [1, 2, 4]\n",
    "\n",
    "for g in gpus:\n",
    "    label = f\"GPU Sweep ({PREDICT_SIZE} sample images)\"\n",
    "    sub_label = f\"{g} GPU\"\n",
    "\n",
    "    executor = submitit.AutoExecutor(folder=\"submitit_logs\", cluster=\"slurm\")\n",
    "    executor.update_parameters(gpus_per_node=g, slurm_partition=\"community\", slurm_account=\"xai\", timeout_min=180)\n",
    "    args = (\n",
    "        app,\n",
    "        (\n",
    "            gen_sliding_window,\n",
    "            True,  # use_accelerate\n",
    "            False,  # display_results\n",
    "            None,\n",
    "        ),  # results_filepath\n",
    "    )\n",
    "    kwargs = {\"num_processes\": g}\n",
    "\n",
    "    print(f\"Starting GPU sweep test: {g} GPU\")\n",
    "    gpu_benchmark_results.append(\n",
    "        benchmark.Timer(\n",
    "            stmt=\"run_app(app, *args, **kwargs)\",\n",
    "            setup=\"from __main__ import run_app\",\n",
    "            globals={\"app\": app, \"args\": args, \"kwargs\": kwargs},\n",
    "            label=label,\n",
    "            sub_label=sub_label,\n",
    "            description=\"time\",\n",
    "        ).blocked_autorange(min_run_time=min_run_time)\n",
    "    )\n",
    "\n",
    "compare = benchmark.Compare(gpu_benchmark_results)\n",
    "compare.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e885705-7c94-4ba9-b4d0-1797dc0ef04d",
   "metadata": {},
   "source": [
    "### Mask Sweep <a name=\"mask-sweep\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c66eded8-89d9-463a-b4db-d85dd1efb04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting number masks test: 50 masks\n",
      "Starting number masks test: 100 masks\n",
      "Starting number masks test: 200 masks\n",
      "Starting number masks test: 400 masks\n",
      "[ Mask Sweep (100 sample images) ]\n",
      "                 |  time\n",
      "1 threads: -------------\n",
      "      50 Masks   |  14.2\n",
      "      100 Masks  |  20.2\n",
      "      200 Masks  |  36.3\n",
      "      400 Masks  |  60.3\n",
      "\n",
      "Times are in seconds (s).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mask_benchmark_results = []\n",
    "\n",
    "n_masks = [50, 100, 200, 400]\n",
    "gpus = 4\n",
    "\n",
    "for n in n_masks:\n",
    "    label = f\"Mask Sweep ({PREDICT_SIZE} sample images)\"\n",
    "    sub_label = f\"{n} Masks\"\n",
    "\n",
    "    executor = submitit.AutoExecutor(folder=\"submitit_logs\", cluster=\"slurm\")\n",
    "    executor.update_parameters(gpus_per_node=gpus, slurm_partition=\"community\", slurm_account=\"xai\", timeout_min=180)\n",
    "    kwargs = {\"num_processes\": gpus}\n",
    "\n",
    "    gen_rise_stack = RISEStack(n=n, s=8, p1=0.5, seed=0, threads=4)\n",
    "\n",
    "    print(f\"Starting number masks test: {n} masks\")\n",
    "    args = (\n",
    "        app,\n",
    "        (\n",
    "            gen_rise_stack,\n",
    "            True,  # use_accelerate\n",
    "            False,  # display_results\n",
    "            None,\n",
    "        ),  # results_filepath\n",
    "    )\n",
    "    mask_benchmark_results.append(\n",
    "        benchmark.Timer(\n",
    "            stmt=\"run_app(app, *args, **kwargs)\",\n",
    "            setup=\"from __main__ import run_app\",\n",
    "            globals={\"app\": app, \"args\": args, \"kwargs\": kwargs},\n",
    "            label=label,\n",
    "            sub_label=sub_label,\n",
    "            description=\"time\",\n",
    "        ).blocked_autorange(min_run_time=min_run_time)\n",
    "    )\n",
    "\n",
    "compare = benchmark.Compare(mask_benchmark_results)\n",
    "compare.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f50fed-9609-4cf1-a23e-21c441df6138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
