{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dca4823-056c-46dd-aa42-155e0efd4001",
   "metadata": {},
   "source": [
    "# Exploring `pytorch-lightning` With `xaitk-saliency` Integration\n",
    "\n",
    "This example extends the \"PyTorch Lightning DataModules\" notebook, found [here](https://github.com/Lightning-AI/tutorials/blob/publication/.notebooks/lightning_examples/datamodules.ipynb), for multi-GPU based training. Additionally, this notebook will explore integrating `xaitk-saliency` and `pytorch-lightning` to generate saliency maps for model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854c8ff9-a8e1-47cd-a30d-cecd6cd7be39",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Environment Setup](#environment-setup)\n",
    "* [Imports](#imports)\n",
    "* [Introduction](#introduction)\n",
    "  * [Defining the `MNISTDataModule`](#defining-mnist-data-module)\n",
    "  * [Defining the Dataset Agnostic `LitModel`](#defining-dataset-agnostic-lit-model)\n",
    "    * [Accelerator Code Preparation](#accelerator-code-preparation)\n",
    "  * [Training `LitModel` Using the `MNISTDataModule`](#training-lit-model-for-mnist)\n",
    "    * [PyTorch Lightning's Trainer](#pytorch-lightnings-trainer)\n",
    "    * [Accelerators and Distributed Modes](#accelerators-and-distributed-modes)\n",
    "      * [Selecting Devices](#selecting-accelerator-devices)\n",
    "      * [Distributed Modes](#distributed-modes)\n",
    "  * [Defining the `CIFAR10DataModule`](#defining-cifar10-data-module)\n",
    "  * [Training `LitModel` Using the `CIFAR10DataModule`](#training-lit-model-for-cifar10)\n",
    "  * [`xaitk-saliency` Integration](#xaitk-integration)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4cb88a-db8a-4676-8e74-cb4b9bf0237d",
   "metadata": {},
   "source": [
    "## Environment Setup <a name=\"environment-setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6150f765-a61b-430d-b27c-0dbb9a04c352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing torchmetrics...\n",
      "Installing ipython...\n",
      "Installing setuptools...\n",
      "Installing torch...\n",
      "Installing pytorch-lightning...\n",
      "Installing torchvision...\n",
      "Installing xaitk-saliency...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -qU pip\n",
    "print(\"Installing torchmetrics...\")\n",
    "!{sys.executable} -m pip install -q 'torchmetrics>=0.7'\n",
    "print(\"Installing ipython...\")\n",
    "!{sys.executable} -m pip install -q ipython[notebook]\n",
    "print(\"Installing setuptools...\")\n",
    "!{sys.executable} -m pip install -q 'setuptools==59.5.0'\n",
    "print(\"Installing torch...\")\n",
    "!{sys.executable} -m pip install -q 'torch>=1.8'\n",
    "print(\"Installing pytorch-lightning...\")\n",
    "!{sys.executable} -m pip install -q 'pytorch-lightning>=1.4'\n",
    "print(\"Installing torchvision...\")\n",
    "!{sys.executable} -m pip install -q torchvision\n",
    "print(\"Installing xaitk-saliency...\")\n",
    "!{sys.executable} -m pip install -q xaitk-saliency\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cc9a40-6d3b-49d1-9d3a-2c6e4c8c8186",
   "metadata": {},
   "source": [
    "## Imports <a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d0b5b3-f7fd-4b14-bb37-e26abcfd5d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchmetrics.functional import accuracy\n",
    "from torchvision import transforms\n",
    "\n",
    "# Note you must have torchvision installed for this example\n",
    "from torchvision.datasets import CIFAR10, MNIST\n",
    "\n",
    "# xaitk-saliency integration imports\n",
    "from smqtk_classifier import ClassifyImage\n",
    "from typing import Iterable, Dict, Hashable, Tuple\n",
    "from xaitk_saliency.impls.gen_image_classifier_blackbox_sal.slidingwindow import SlidingWindowStack\n",
    "from xaitk_saliency import GenerateImageClassifierBlackboxSaliency\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda097e-f735-45dd-9158-d6cab0210f03",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "A `LightningModule` _is_ a PyTorch `nn.Module`, with additional features. A `LightningDataModule` is a way of decoupling data-related hooks from the `LightningModule` to develop dataset agnostic models. In this notebook, we'll define two `DataModule`s to showcase this dataset agnostic capability.\n",
    "\n",
    "### Defining the `MNISTDataModule` <a name=\"defining-mnist-data-module\"></a>\n",
    "\n",
    "First, we'll define an MNIST `LightningDataModule`. There are various components to a `LightningDataModule`:\n",
    "\n",
    "* `__init__`\n",
    "  * Takes in a `data_dir` arg that points to where you have downloaded/wish to download the MNIST dataset.\n",
    "  * Defines a transform that will be applied across train, val, and test dataset splits.\n",
    "  * Defines default `self.dims`.\n",
    "* [`prepare_data()`](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html#prepare-data)\n",
    "  * This is where we can download the dataset. We point to our desired dataset and ask torchvision's MNIST dataset class to download if the dataset isn't found there.\n",
    "  * __Note we do not make any state assignments in this function__ (i.e. `self.something = ...`)\n",
    "* [`setup(stage)`](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html#setup)\n",
    "  * Loads in data from file and prepares PyTorch tensor datasets for each split (train, val, test).\n",
    "  * Setup expects a 'stage' arg which is used to separate logic for 'fit' and 'test'.\n",
    "  * If you don't mind loading all your datasets at once, you can set up a condition to allow for both 'fit' related setup and 'test' related setup to run whenever `None` is passed to `stage`.\n",
    "  * __Note this runs across all GPUs and it _is_ safe to make state assignments here__\n",
    "* [`x_dataloader()`](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.core.hooks.DataHooks.html#pytorch_lightning.core.hooks.DataHooks.train_dataloader)\n",
    "  * `train_dataloader()`, `val_dataloader()`, and `test_dataloader()` all return PyTorch `DataLoader` instances that are created by wrapping their respective datasets that we prepared in `setup()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3b1ffc-3204-4fc7-b220-2b118fd68ce3",
   "metadata": {},
   "source": [
    "Note: If the `ddp_notebook` or `ddp_fork` distributed mode is used, GPU operations such as moving tensors to the GPU or calling `torch.cuda` functions before invoking `Trainer.fit` are not allowed so we will avoid doing so now (more on distributed modes later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fb25cc0-2d9a-4d32-be6d-0df2c7217904",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n",
    "#BATCH_SIZE = 256 if torch.cuda.is_available() else 64\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c225388-ef15-44ba-ae2d-82f44226103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(LightningDataModule):\n",
    "    def __init__(self, data_dir: str = PATH_DATASETS):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dims = (1, 28, 28)\n",
    "        self.num_classes = 10\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=BATCH_SIZE)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    def get_transform(self):\n",
    "        return self.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e319b-a194-4105-8140-c493a3345c80",
   "metadata": {},
   "source": [
    "### Defining the Dataset Agnostic `LitModel` <a name=\"defining-dataset-agnostic-lit-model\"></a>\n",
    "\n",
    "Below we define the same `LitMNIST` model as was defined in [PyTorch Lightning's MNIST Hello World Notebook](https://github.com/Lightning-AI/tutorials/blob/publication/.notebooks/lightning_examples/mnist-hello-world.ipynb). However, this time our model has the freedom to use any input data we'd like. We'll also make some slight modifications to the model, noted in the following section, to ensure our model can scale without changes.\n",
    "\n",
    "#### [Accelerator Code Preparation <a name=\"accelerator-code-preparation\"></a>](https://pytorch-lightning.readthedocs.io/en/latest/accelerators/accelerator_prepare.html)\n",
    "\n",
    "There are some code preparation details to keep in mind to train on any accelerator without changing code, summarized here:\n",
    "\n",
    "* Remove any `.cuda()` or `.to()` calls\n",
    "* Init tensors using `type_as` and `register_buffer`\n",
    "* Remove samplers\n",
    "* Syncronize validation and test logging (add `sync_dist=True` to all `self.log` calls in the validation and test step)\n",
    "* Make models pickleable\n",
    "\n",
    "We'll make those sure we're following those guidelines here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5268a40-0e3f-4239-b009-773a4d11994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(LightningModule):\n",
    "    def __init__(self, channels, width, height, num_classes, hidden_size=64, learning_rate=2e-4):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # We take in input dimensions as parameters and use those to dynamically build model.\n",
    "        self.channels = channels\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels * width * height, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, sync_dist=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, sync_dist=True)\n",
    "        \n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        # this calls forward\n",
    "        return self(batch)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611feb97-f047-491b-a0cb-c6563d92b3f9",
   "metadata": {},
   "source": [
    "### Training `LitModel` Using the `MNISTDataModule` <a name=\"training-lit-model-for-mnist\"></a>\n",
    "\n",
    "Now, we initialize and train the `LitModel` using the `MNISTDataModule`'s configuration settings and dataloaders.\n",
    "\n",
    "#### PyTorch Lightning's Trainer <a name=\"pytorch-lightnings-trainer\"></a>\n",
    "\n",
    "The [trainer](https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html) automates much of what is done manually in vanilla PyTorch once our model is organized within a `LightningModule`. If there's any key part you don't want automated, the trainer allows overrides.\n",
    "\n",
    "Under the hood, the trainer handles training details including:\n",
    "- Automatically enabling/disabling grads\n",
    "- Running the training, validation, and test dataloaders\n",
    "- Calling the callbacks at the appropriate times\n",
    "- Putting batches and computations on the correct devices\n",
    "\n",
    "[`.fit(..)`](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html#pytorch_lightning.trainer.trainer.Trainer.fit) runs the whole optimization routine.\n",
    "\n",
    "Basic trainer usage:\n",
    "```\n",
    "model = MyLightningModule()\n",
    "\n",
    "trainer = Trainer()\n",
    "trainer.fit(model, my_data_module)\n",
    "```\n",
    "\n",
    "#### Accelerators and Distibuted Modes <a name=\"accelerators-and-distributed-modes\"></a>\n",
    "\n",
    "Since we followed the acclerator code preparation notes above, we can easily train our model on any number/type of accelerator device(s).\n",
    "\n",
    "##### [Selecting Accelerator Devices <a name=\"selecting-accelerator-devices\"></a>](https://pytorch-lightning.readthedocs.io/en/latest/accelerators/gpu_basic.html)\n",
    "\n",
    "You can select devices using ranges, a list of indices or a string containing a comma separated list of device ids:\n",
    "\n",
    "```\n",
    "# Default (int) specifies how many devices to use per node\n",
    "Trainer(accelerator=\"gpu\", devices=k)\n",
    "\n",
    "# Above is equivalant to\n",
    "Trainer(accelerator=\"gpu\", devices=list(range(k)))\n",
    "\n",
    "# Specify which devices to use (don't use when running on cluster)\n",
    "Trainer(accelerator=\"gpu\", devices=[0, 1])\n",
    "\n",
    "# String equivalent\n",
    "Trainer(accelerator=\"gpu\", devices='0, 1')\n",
    "\n",
    "# To use all available devices put -1 or '-1'\n",
    "# equivalent to list(range(torch.cuda.device_count()))\n",
    "Trainer(accelerator=\"gpu\", devices=-1)\n",
    "```\n",
    "\n",
    "Supported accelerators include: cpu, gpu, tpu, ipu, hpu, mps, auto and custom accelerator instances.\n",
    "\n",
    "##### [Distributed Modes <a name=\"distributed-modes\"></a>](https://pytorch-lightning.readthedocs.io/en/latest/accelerators/gpu_intermediate.html)\n",
    "\n",
    "PyTorch Lightning supports multiple ways of doing distributed training.\n",
    "\n",
    "* Data Parallel (`strategy='dp'`) (multiple-gpus, 1 machine)\n",
    "* Distributed Data Parallel (multiple-gpus across many machines)\n",
    "  * Regular (`strategy='ddp'`)\n",
    "  * Spawn (`strategy='ddp_spawn'`) (automatically used when no mode is set but multiple devices requested)\n",
    "  * Notebook/Fork (`strategy='ddp_notebook'`) (note Windows is not supported)\n",
    "* Horovod (`strategy='horovod'`) (multi-machine, multi-gpu, configured at runtime)\n",
    "* Bagua (`strategy='bagua'`) (multiple-gpus across many machines with advanced training algorithms)\n",
    "\n",
    "__Note only `dp` and `ddp_notebook` strategies can be used in interactive environments such as notebooks__\n",
    "\n",
    "`ddp` is the usual recommended go-to strategy for its speed and stability but it can only be used with scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "189be161-1110-4473-963a-f2b907750d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 55.1 K\n",
      "-------------------------------------\n",
      "55.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.1 K    Total params\n",
      "0.220     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khq.kitware.com/emily.veenhuis/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/khq.kitware.com/emily.veenhuis/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ba0e4634d24e19b697c2107be7a7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "# Init DataModule\n",
    "mnist_dm = MNISTDataModule()\n",
    "# Init model from datamodule's attributes\n",
    "mnist_model = LitModel(*mnist_dm.dims, mnist_dm.num_classes)\n",
    "# Init trainer\n",
    "mnist_trainer = Trainer(\n",
    "    max_epochs=3,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=20)],\n",
    "    accelerator=\"auto\",\n",
    "    devices=-1,\n",
    "    strategy=\"dp\",\n",
    ")\n",
    "# Pass the datamodule as arg to trainer.fit to override model hooks :)\n",
    "mnist_trainer.fit(mnist_model, mnist_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedc8924-57ca-4bf4-8a82-5e371473fde7",
   "metadata": {},
   "source": [
    "### Defining the `CIFAR10DataModule` <a name=\"defining-cifar10-data-module\"></a>\n",
    "\n",
    "Prove `LitModel` is dataset agnostic by defining a new `DataModule` for the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8722128-5269-4ad0-9014-eb1164eceb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10DataModule(LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"./\"):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dims = (3, 32, 32)\n",
    "        self.num_classes = 10\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        CIFAR10(self.data_dir, train=False, download=True)\n",
    "        CIFAR10(self.data_dir, train=True, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            cifar_full = CIFAR10(self.data_dir, train=True, transform=self.transform)\n",
    "            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage == \"predict\" or stage is None:\n",
    "            cifar_full_test = CIFAR10(self.data_dir, train=False, transform=self.transform)\n",
    "            predict_size = 20\n",
    "            test_size = len(cifar_full_test) - predict_size\n",
    "            self.cifar_test, self.cifar_predict = random_split(cifar_full_test, [test_size, predict_size], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.cifar_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.cifar_val, batch_size=BATCH_SIZE)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.cifar_test, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.cifar_predict, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    def get_transform(self):\n",
    "        return self.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f35034c-f668-401d-bdd9-5995386f2021",
   "metadata": {},
   "source": [
    "### Training `LitModel` using the `CIFAR10DataModule` <a name=\"training-lit-model-for-cifar10\"></a>\n",
    "\n",
    "This model isn't very good, so it will perform badly on the CIFAR10 dataset.\n",
    "\n",
    "The point here is that we can see our `LitModel` has no problem using a different datamodule as its input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d1d63df-059e-4b8d-9ab5-478659f15a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 855 K \n",
      "-------------------------------------\n",
      "855 K     Trainable params\n",
      "0         Non-trainable params\n",
      "855 K     Total params\n",
      "3.420     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khq.kitware.com/emily.veenhuis/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/khq.kitware.com/emily.veenhuis/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44996ea581c74bb58a691880dd643e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "cifar10_dm = CIFAR10DataModule()\n",
    "cifar10_model = LitModel(*cifar10_dm.dims, cifar10_dm.num_classes, hidden_size=256)\n",
    "tqdm_progress_bar = TQDMProgressBar(refresh_rate=20)\n",
    "cifar10_trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"auto\",\n",
    "    devices=-1,\n",
    "    strategy=\"dp\",\n",
    "    callbacks=[tqdm_progress_bar],\n",
    ")\n",
    "cifar10_trainer.fit(cifar10_model, cifar10_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38169815-3f22-43a0-9524-0ee1db1f1c45",
   "metadata": {},
   "source": [
    "## `xaitk-saliency` Integration <a name=\"xaitk-integration\"></a>\n",
    "\n",
    "### `ClassifyImage` Implementation <a name=\"classifyimage-implementation\"></a>\n",
    "\n",
    "To use the selected model with the `GenerateImageClassifierBlackboxSaliency` interface, we need to create an implementation of `ClassifyImage` that wraps the underlying model. The core method that requires implementation is `classify_images()` which takes images and returns predictions for each image in the format defined by the interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cee879e-9a19-4c92-8646-36d1a0425308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchLightningClassifier(ClassifyImage):\n",
    "    def __init__(\n",
    "        self,\n",
    "        trainer,\n",
    "        transform = None,\n",
    "        model = None,\n",
    "    ):\n",
    "        self.trainer = trainer\n",
    "        self.transform = transform\n",
    "        self.model = model\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return list(range(10))\n",
    "    \n",
    "    class ClassifyImagesDataset(Dataset):\n",
    "        def __init__(self, imgs, transform=None):\n",
    "            self.imgs = list(imgs)\n",
    "            self.transform = transform\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self.imgs)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            image = self.imgs[idx]\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "\n",
    "    def classify_images(self, image_iter):\n",
    "        print(type(image_iter))\n",
    "        dataloader = DataLoader(self.ClassifyImagesDataset(image_iter, self.transform), batch_size=BATCH_SIZE, shuffle=False)\n",
    "        \n",
    "        if self.model is None:\n",
    "            preds = self.trainer.predict(dataloaders=dataloader)\n",
    "        else:\n",
    "            preds = self.trainer.predict(self.model, dataloaders=dataloader)\n",
    "        \n",
    "        results = []\n",
    "        for p in preds:\n",
    "            max_idx = torch.argmax(p).numpy()\n",
    "            r = {}\n",
    "            for idx in range(p.numpy().size):\n",
    "                if idx == max_idx:\n",
    "                    r[idx] = 1\n",
    "                else:\n",
    "                    r[idx] = 0\n",
    "            results.append(r)\n",
    "            \n",
    "        return results\n",
    "            \n",
    "    # Required for implementation\n",
    "    def get_config(self):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6610bb-2a10-46a5-8252-4b91333ed3c6",
   "metadata": {},
   "source": [
    "### Instantiate Classifier <a name=\"instantiate-classifier\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6a54fbf-e5d6-47ee-acd7-d601e9dd3607",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_classifier = PytorchLightningClassifier(cifar10_trainer, cifar10_dm.get_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20890366-86cb-4446-8b96-e1c725e9cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_slidingWindow = SlidingWindowStack(\n",
    "    window_size=(2, 2),\n",
    "    stride=(1, 1),\n",
    "    threads=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "847d7dca-7163-4a83-8a15-bf9f64880e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def app(\n",
    "    images: np.ndarray,\n",
    "    image_classifier: ClassifyImage,\n",
    "    saliency_generator: GenerateImageClassifierBlackboxSaliency\n",
    "):  \n",
    "\n",
    "    # Generate saliency maps\n",
    "    sal_maps_set = []\n",
    "    for img in images:\n",
    "        sal_maps = saliency_generator(img, image_classifier)\n",
    "        sal_maps_set.append(sal_maps)\n",
    "    \n",
    "    num_classes = sal_maps_set[0].shape[0]\n",
    "    \n",
    "    # Plot first image in set with saliency maps\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.suptitle(\"Heatmaps for First Image\", fontsize=16)\n",
    "    num_cols = np.ceil(num_classes/2).astype(int) + 1\n",
    "    plt.subplot(2, num_cols, 1)\n",
    "    plt.imshow(images[0].reshape(28,28), cmap='gray')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    \n",
    "    for c in range(num_cols - 1):\n",
    "        plt.subplot(2, num_cols, c + 2)\n",
    "        plt.imshow(sal_maps_set[0][c], cmap=plt.cm.RdBu, vmin=-1, vmax=1)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.xlabel(f\"Class {c}\")\n",
    "    for c in range(num_classes - num_cols + 1, num_classes):\n",
    "        plt.subplot(2, num_cols, c + 3)\n",
    "        plt.imshow(sal_maps_set[0][c], cmap=plt.cm.RdBu, vmin=-1, vmax=1)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.xlabel(f\"Class {c}\")\n",
    "    \n",
    "    # Average heatmaps for each respective class\n",
    "    global_maps = np.sum(sal_maps_set, axis=0) / len(images)\n",
    "    \n",
    "    # Plot average maps\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.suptitle(\"Average Heatmaps from All Images\", fontsize=16)\n",
    "    for c in range(num_classes):\n",
    "        vcap = np.absolute(global_maps[i]).max()\n",
    "        plt.subplot(2, num_cols-1, c + 1)\n",
    "        plt.imshow(global_maps[c], cmap=plt.cm.RdBu, vmin=-vcap, vmax=vcap)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.xlabel(f\"Class {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81f32a96-099a-46a1-b1e5-675a6be4e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_full_test = CIFAR10(\"./\", train=False)\n",
    "cifar_full_test_arr = cifar_full_test.data\n",
    "predict_size = 20\n",
    "cifar_predict_arr = cifar_full_test_arr[0:predict_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a93c2397-d9d5-439a-87b2-8359d7d393f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khq.kitware.com/emily.veenhuis/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:129: UserWarning: `.predict(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.predict(ckpt_path='best')` to use the best model or `.predict(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/khq.kitware.com/emily.veenhuis/xaitk-cdao/examples/lightning/lightning_logs/version_79/checkpoints/epoch=4-step=880.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Loaded model weights from checkpoint at /home/khq.kitware.com/emily.veenhuis/xaitk-cdao/examples/lightning/lightning_logs/version_79/checkpoints/epoch=4-step=880.ckpt\n",
      "/home/khq.kitware.com/emily.veenhuis/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa68327935ce4c9c83b89c8d693d2b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 176it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khq.kitware.com/emily.veenhuis/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:129: UserWarning: `.predict(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.predict(ckpt_path='best')` to use the best model or `.predict(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/khq.kitware.com/emily.veenhuis/xaitk-cdao/examples/lightning/lightning_logs/version_79/checkpoints/epoch=4-step=880.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Loaded model weights from checkpoint at /home/khq.kitware.com/emily.veenhuis/xaitk-cdao/examples/lightning/lightning_logs/version_79/checkpoints/epoch=4-step=880.ckpt\n",
      "/home/khq.kitware.com/emily.veenhuis/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828a4824b15c475f8dbdd085c21ba988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 176it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'divide' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mapp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcifar_predict_arr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcifar10_classifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgen_slidingWindow\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mapp\u001b[0;34m(images, image_classifier, saliency_generator)\u001b[0m\n\u001b[1;32m      8\u001b[0m sal_maps_set \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[0;32m---> 10\u001b[0m     sal_maps \u001b[38;5;241m=\u001b[39m \u001b[43msaliency_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_classifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     sal_maps_set\u001b[38;5;241m.\u001b[39mappend(sal_maps)\n\u001b[1;32m     13\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m sal_maps_set[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/xaitk_saliency/interfaces/gen_image_classifier_blackbox_sal.py:88\u001b[0m, in \u001b[0;36mGenerateImageClassifierBlackboxSaliency.__call__\u001b[0;34m(self, ref_image, blackbox)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     81\u001b[0m     ref_image: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m     82\u001b[0m     blackbox: ClassifyImage\n\u001b[1;32m     83\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    Alias to the :meth:`generate` method.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    See :meth:`generate` for more details.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblackbox\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/xaitk_saliency/interfaces/gen_image_classifier_blackbox_sal.py:69\u001b[0m, in \u001b[0;36mGenerateImageClassifierBlackboxSaliency.generate\u001b[0;34m(self, ref_image, blackbox)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ref_image\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput image matrix has an unexpected number of dimensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_image\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblackbox\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Check that the saliency heatmaps' shape matches the reference image.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m!=\u001b[39m ref_image\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/xaitk_saliency/impls/gen_image_classifier_blackbox_sal/slidingwindow.py:54\u001b[0m, in \u001b[0;36mSlidingWindowStack._generate\u001b[0;34m(self, ref_image, blackbox)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\u001b[38;5;28mself\u001b[39m, ref_image: np\u001b[38;5;241m.\u001b[39mndarray, blackbox: ClassifyImage) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_po\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblackbox\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/xaitk_saliency/interfaces/gen_image_classifier_blackbox_sal.py:69\u001b[0m, in \u001b[0;36mGenerateImageClassifierBlackboxSaliency.generate\u001b[0;34m(self, ref_image, blackbox)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ref_image\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput image matrix has an unexpected number of dimensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_image\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblackbox\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Check that the saliency heatmaps' shape matches the reference image.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m!=\u001b[39m ref_image\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/xaitk_saliency/impls/gen_image_classifier_blackbox_sal/occlusion_based.py:78\u001b[0m, in \u001b[0;36mPerturbationOcclusion._generate\u001b[0;34m(self, ref_image, blackbox)\u001b[0m\n\u001b[1;32m     74\u001b[0m     pert_conf_mat[i] \u001b[38;5;241m=\u001b[39m [pc[la] \u001b[38;5;28;01mfor\u001b[39;00m la \u001b[38;5;129;01min\u001b[39;00m class_list]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Compose classification results into a matrix for the generator\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# algorithm.\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref_conf_vec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpert_conf_mat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperturbation_masks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/xaitk_saliency/interfaces/gen_classifier_conf_sal.py:92\u001b[0m, in \u001b[0;36mGenerateClassifierConfidenceSaliency.__call__\u001b[0;34m(self, image_conf, perturbed_conf, perturbed_masks)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     85\u001b[0m     image_conf: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m     86\u001b[0m     perturbed_conf: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m     87\u001b[0m     perturbed_masks: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    Alias for :meth:`.GenerateClassifierConfidenceSaliency.generate`.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturbed_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturbed_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/xaitk_saliency/impls/gen_classifier_conf_sal/occlusion_scoring.py:44\u001b[0m, in \u001b[0;36mOcclusionScoring.generate\u001b[0;34m(self, image_conf, perturbed_conf, perturbed_masks)\u001b[0m\n\u001b[1;32m     41\u001b[0m diff \u001b[38;5;241m=\u001b[39m image_conf \u001b[38;5;241m-\u001b[39m perturbed_conf\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Weighting perturbed regions with respective difference in confidence\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m sal \u001b[38;5;241m=\u001b[39m \u001b[43mweight_regions_by_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturbed_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Normalize final saliency map\u001b[39;00m\n\u001b[1;32m     47\u001b[0m sal \u001b[38;5;241m=\u001b[39m maxabs_scale(\n\u001b[1;32m     48\u001b[0m     sal\u001b[38;5;241m.\u001b[39mreshape(sal\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     49\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     50\u001b[0m )\u001b[38;5;241m.\u001b[39mreshape(sal\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-lightning-test/lib/python3.9/site-packages/xaitk_saliency/utils/masking.py:341\u001b[0m, in \u001b[0;36mweight_regions_by_scalar\u001b[0;34m(scalar_vec, masks, inv_masks, normalize)\u001b[0m\n\u001b[1;32m    338\u001b[0m     mask_sum[mask_sum \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;66;03m# Compute final saliency map by normalizing with sampling factor.\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m     sal_across_masks \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m mask_sum\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sal_across_masks\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'divide' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "app(\n",
    "    cifar_predict_arr,\n",
    "    cifar10_classifier,\n",
    "    gen_slidingWindow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e0b354-1abf-481d-ab53-ca66ea05db3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
